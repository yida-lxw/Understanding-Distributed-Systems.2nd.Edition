<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en-GB">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <title>ch028.xhtml</title>
  <link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css" />
</head>
<body epub:type="bodymatter">
<section id="cdn" class="level1" data-number="15">
<h1 data-number="15"><span class="header-section-number">15</span> Content delivery networks</h1>
<p>A CDN is an overlay network of geographically distributed caching servers (reverse proxies) architected around the design limitations of the network protocols that run the internet.</p>
<p>When using a CDN, clients hit URLs that resolve to caching servers that belong to the CDN. When a CDN server receives a request, it checks whether the requested resource is cached locally. If not, the CDN server transparently fetches it from the <em>origin server</em> (i.e., our application server) using the original URL, caches the response locally, and returns it to the client. AWS CloudFront<a href="#fn1" class="footnote-ref" id="fnref1" epub:type="noteref">1</a> and Akamai<a href="#fn2" class="footnote-ref" id="fnref2" epub:type="noteref">2</a> are examples of well-known CDN services.</p>
<section id="overlay-network" class="level2" data-number="15.1">
<h2 data-number="15.1"><span class="header-section-number">15.1</span> Overlay network</h2>
<p>You would think that the main benefit of a CDN is caching, but it’s actually the underlying network substrate. The public internet is composed of thousands of networks, and its core routing protocol, BGP, was not designed with performance in mind. It primarily uses the number of hops to cost how expensive a path is with respect to another, without considering their latencies or congestion.</p>
<p>As the name implies, a CDN is a network. More specifically, an overlay network<a href="#fn3" class="footnote-ref" id="fnref3" epub:type="noteref">3</a> built on top of the internet that exploits a variety of techniques to reduce the response time of network requests and increase the bandwidth of data transfers.</p>
<p>When we first discussed TCP in chapter <a href="#tcp">2</a>, we talked about the importance of minimizing the latency between a client and a server. No matter how fast the server is, if the client is located on the other side of the world from it, the response time is going to be over 100 ms just because of the network latency, which is physically limited by the speed of light. Not to mention the increased error rate when sending data across the public internet over long distances.</p>
<p>This is why CDN clusters are placed in multiple geographical locations to be closer to clients. But how do clients know which cluster is closest to them? One way is via <em>global DNS load balancing</em><a href="#fn4" class="footnote-ref" id="fnref4" epub:type="noteref">4</a>: an extension to DNS that considers the location of the client inferred from its IP, and returns a list of the geographically closest clusters taking into account also the network congestion and the clusters’ health.</p>
<p>CDN servers are also placed at <em>internet exchange points</em>, where ISPs connect to each other. That way, virtually the entire communication from the origin server to the clients flows over network links that are part of the CDN, and the brief hops on either end have low latencies due to their short distance.</p>
<p>The routing algorithms of the overlay network are optimized to select paths with reduced latencies and congestion, based on continuously updated data about the health of the network. Additionally, TCP optimizations are exploited where possible, such as using pools of persistent connections between servers to avoid the overhead of setting up new connections and using optimal TCP window sizes to maximize the effective bandwidth (see Figure <a href="#fig:cdn">15.1</a>).</p>
<div class="figure" style="text-align: center">
<img alt="A CDN reduces the round trip time of network calls for clients and the load for the origin server." width="100%" src="../media/file38.png" />
<p class="caption">
Figure 15.1: A CDN reduces the round trip time of network calls for clients and the load for the origin server.
</p>
</div>
<p>The overlay network can also be used to speed up the delivery of dynamic resources that cannot be cached. In this capacity, the CDN becomes the frontend for the application, shielding it against distributed denial-of-service (DDoS) attacks<a href="#fn5" class="footnote-ref" id="fnref5" epub:type="noteref">5</a>.</p>
</section>
<section id="caching" class="level2" data-number="15.2">
<h2 data-number="15.2"><span class="header-section-number">15.2</span> Caching</h2>
<p>A CDN can have multiple content caching layers. The top layer is made of edge clusters deployed at different geographical locations, as mentioned earlier. But infrequently accessed content might not be available at the edge, in which case the edge servers must fetch it from the origin server. Thanks to the overlay network, the content can be fetched more efficiently and reliably than what the public internet would allow.</p>
<p>There is a tradeoff between the number of edge clusters and the cache <em>hit ratio</em><a href="#fn6" class="footnote-ref" id="fnref6" epub:type="noteref">6</a>, i.e., the likelihood of finding an object in the cache. The higher the number of edge clusters, the more geographically dispersed clients they can serve, but the lower the cache hit ratio will be, and consequently, the higher the load on the origin server. To alleviate this issue, the CDN can have one or more intermediary caching clusters deployed in a smaller number of geographical locations, which cache a larger fraction of the original content.</p>
<p>Within a CDN cluster, the content is partitioned among multiple servers so that each one serves only a specific subset of it; this is necessary as no single server would be able to hold all the data. Because data partitioning is a core scalability pattern, we will take a closer look at it in the next chapter.</p>
</section>
</section>
<section class="footnotes" epub:type="footnotes">
<hr />
<ol>
<li id="fn1" epub:type="footnote"><p>“Amazon CloudFront,” <a href="https://aws.amazon.com/cloudfront/" class="uri">https://aws.amazon.com/cloudfront/</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" epub:type="footnote"><p>“Akamai,” <a href="https://www.akamai.com/" class="uri">https://www.akamai.com/</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" epub:type="footnote"><p>“The Akamai Network: A Platform for HighPerformance Internet Applications,” <a href="https://groups.cs.umass.edu/ramesh/wp-content/uploads/sites/3/2019/12/The-akamai-network-a-platform-for-high-performance-internet-applications.pdf" class="uri">https://groups.cs.umass.edu/ramesh/wp-content/uploads/sites/3/2019/12/The-akamai-network-a-platform-for-high-performance-internet-applications.pdf</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" epub:type="footnote"><p>“Load Balancing at the Frontend,” <a href="https://landing.google.com/sre/sre-book/chapters/load-balancing-frontend/" class="uri">https://landing.google.com/sre/sre-book/chapters/load-balancing-frontend/</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" epub:type="footnote"><p>“Denial-of-service attack,” <a href="https://en.wikipedia.org/wiki/Denial-of-service_attack" class="uri">https://en.wikipedia.org/wiki/Denial-of-service_attack</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" epub:type="footnote"><p>A cache hit occurs when the requested data can be found in the cache, while a cache miss occurs when it cannot.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
