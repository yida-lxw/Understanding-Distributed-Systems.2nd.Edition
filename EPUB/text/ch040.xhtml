<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en-GB">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <title>ch040.xhtml</title>
  <link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css" />
</head>
<body epub:type="bodymatter">
<section id="failure-causes" class="level1" data-number="24">
<h1 data-number="24"><span class="header-section-number">24</span> Common failure causes</h1>
<p>We say that a system has a <em>failure</em><a href="#fn1" class="footnote-ref" id="fnref1" epub:type="noteref">1</a> when it no longer provides a service to its users that meets its specification. A failure is caused by a <em>fault</em>: a failure of an internal component or an external dependency the system depends on. Some faults can be tolerated and have no user-visible impact at all, while others lead to failures.</p>
<p>To build fault-tolerant applications, we first need to have an idea of what can go wrong. In the next few sections, we will explore some of the most common root causes of failures. By the end of it, you will likely wonder how to tolerate all these different types of faults. The answers will follow in the next few chapters.</p>
<!-- TODO: make sure use of fault and failure is consistent across book -->
<section id="hardware-faults" class="level2" data-number="24.1">
<h2 data-number="24.1"><span class="header-section-number">24.1</span> Hardware faults</h2>
<p>Any physical part of a machine can fail. HDDs, memory modules, power supplies, motherboards, SSDs, NICs, or CPUs, can all stop working for various reasons. In some cases, hardware faults can cause data corruption as well. If that wasn’t enough, entire data centers can go down because of power cuts or natural disasters.</p>
<p>As we will discuss later, we can address many of these infrastructure faults with redundancy. You would think that these faults are the main cause for distributed applications failing, but in reality, they often fail for very mundane reasons.</p>
</section>
<section id="incorrect-error-handling" class="level2" data-number="24.2">
<h2 data-number="24.2"><span class="header-section-number">24.2</span> Incorrect error handling</h2>
<p>A study from 2014<a href="#fn2" class="footnote-ref" id="fnref2" epub:type="noteref">2</a> of user-reported failures from five popular distributed data stores found that the majority of catastrophic failures were the result of incorrect handling of non-fatal errors.</p>
<p>In most cases, the bugs in the error handling could have been detected with simple tests. For example, some handlers completely ignored errors. Others caught an overly generic exception, like <em>Exception</em> in Java, and aborted the entire process for no good reason. And some other handlers were only partially implemented and even contained “FIXME” and “TODO” comments.</p>
<p>In hindsight, this is perhaps not too surprising, given that error handling tends to be an afterthought.<a href="#fn3" class="footnote-ref" id="fnref3" epub:type="noteref">3</a> Later, in chapter <a href="#testing">29</a>, we will take a closer look at best practices for testing large distributed applications.</p>
</section>
<section id="configuration-changes" class="level2" data-number="24.3">
<h2 data-number="24.3"><span class="header-section-number">24.3</span> Configuration changes</h2>
<p>Configuration changes are one of the leading root causes for catastrophic failures<a href="#fn4" class="footnote-ref" id="fnref4" epub:type="noteref">4</a>. It’s not just misconfigurations that cause problems, but also valid configuration changes to enable rarely-used features that no longer work as expected (or never did).</p>
<p>What makes configuration changes particularly dangerous is that their effects can be delayed<a href="#fn5" class="footnote-ref" id="fnref5" epub:type="noteref">5</a>. If an application reads a configuration value only when it’s actually needed, an invalid value might take effect only hours or days after it has changed and thus escape early detection.</p>
<p>This is why configuration changes should be version-controlled, tested, and released just like code changes, and their validation should happen preventively when the change happens. In chapter <a href="#cd">30</a>, we will discuss safe release practices for code and configuration changes in the context of continuous deployments.</p>
</section>
<section id="single-points-of-failure" class="level2" data-number="24.4">
<h2 data-number="24.4"><span class="header-section-number">24.4</span> Single points of failure</h2>
<p>A single point of failure (SPOF) is a component whose failure brings the entire system down with it. In practice, systems can have multiple SPOFs.</p>
<p>Humans make for great SPOFs, and if you put them in a position where they can cause a catastrophic failure on their own, you can bet they eventually will. For example, human failures often happen when someone needs to manually execute a series of operational steps in a specific order without making any mistakes. On the other hand, computers are great at executing instructions, which is why automation should be leveraged whenever possible.</p>
<p>Another common SPOF is DNS<a href="#fn6" class="footnote-ref" id="fnref6" epub:type="noteref">6</a>. If clients can’t resolve the domain name for an application, they won’t be able to connect to it. There are many reasons why that can happen, ranging from domain names expiring<a href="#fn7" class="footnote-ref" id="fnref7" epub:type="noteref">7</a> to entire root level domains going down<a href="#fn8" class="footnote-ref" id="fnref8" epub:type="noteref">8</a>.</p>
<p>Similarly, the TLS certificate used by an application for its HTTP endpoints is also a SPOF<a href="#fn9" class="footnote-ref" id="fnref9" epub:type="noteref">9</a>. If the certificate expires, clients won’t be able to open a secure connection with the application.</p>
<p>Ideally, SPOFs should be identified when the system is designed. The best way to detect them is to examine every system component and ask what would happen if it were to fail. Some SPOFs can be architected away, e.g., by introducing redundancy, while others can’t. In that case, the only option left is to reduce the SPOF’s blast radius, i.e., the damage the SPOF inflicts on the system when it fails. Many of the resiliency patterns we will discuss later reduce the blast radius of failures.</p>
</section>
<section id="network-faults" class="level2" data-number="24.5">
<h2 data-number="24.5"><span class="header-section-number">24.5</span> Network faults</h2>
<p>When a client sends a request to a server, it expects to receive a response from it a while later. In the best case, it receives the response shortly after sending the request. If that doesn’t happen, the client has two options: continue to wait or fail the request with a time-out exception or error.</p>
<p>As discussed in chapter <a href="#failure">7</a>, when the concepts of failure detection and timeouts were introduced, there are many reasons for not getting a prompt response. For example, the server could be very slow or have crashed while processing the request; or maybe the network could be losing a small percentage of packets, causing lots of retransmissions and delays.</p>
<p>Slow network calls are the silent killers<a href="#fn10" class="footnote-ref" id="fnref10" epub:type="noteref">10</a> of distributed systems. Because the client doesn’t know whether the response will eventually arrive, it can spend a long time waiting before giving up, if it gives up at all, causing performance degradations that are challenging to debug. This kind of fault is also referred to as a <em>gray failure</em><a href="#fn11" class="footnote-ref" id="fnref11" epub:type="noteref">11</a>: a failure that is so subtle that it can’t be detected quickly or accurately. Because of their nature, gray failures can easily bring an entire system down to its knees.</p>
<p>In the next section, we will explore another common cause of gray failures.</p>
</section>
<section id="resource-leaks" class="level2" data-number="24.6">
<h2 data-number="24.6"><span class="header-section-number">24.6</span> Resource leaks</h2>
<p>From an observer’s point of view, a very slow process is not very different from one that isn’t running at all — neither can perform useful work. Resource leaks are one of the most common causes of slow processes.</p>
<p>Memory is arguably the most well-known resource affected by leaks. A memory leak causes a steady increase in memory consumption over time. Even languages with garbage collection are vulnerable to leaks: if a reference to an object that is no longer needed is kept somewhere, the garbage collector won’t be able to delete it. When a leak has consumed so much memory that there is very little left, the operating system will start to swap memory pages to disk aggressively. Also, the garbage collector will kick in more frequently, trying to release memory. All of this consumes CPU cycles and makes the process slower. Eventually, when there is no more physical memory left, and there is no more space in the swap file, the process won’t be able to allocate memory, and most operations will fail.</p>
<p>Memory is just one of the many resources that can leak. Take thread pools, for example: if a thread acquired from a pool makes a synchronous blocking HTTP call without a timeout and the call never returns, the thread won’t be returned to the pool. And since the pool has a limited maximum size, it will eventually run out of threads if it keeps losing them.</p>
<p>You might think that making <em>asynchronous</em> calls rather than synchronous ones would help in the previous case. However, modern HTTP clients use socket pools to avoid recreating TCP connections and paying a performance fee, as discussed in chapter <a href="#tcp">2</a>. If a request is made without a timeout, the connection is never returned to the pool. As the pool has a limited maximum size, eventually, there won’t be any connections left.</p>
<p>On top of that, your code isn’t the only thing accessing memory, threads, and sockets. The libraries your application depends on use the same resources, and they can hit the same issues we just discussed.</p>
</section>
<section id="load-pressure" class="level2" data-number="24.7">
<h2 data-number="24.7"><span class="header-section-number">24.7</span> Load pressure</h2>
<p>Every system has a limit of how much load it can withstand, i.e., its capacity. So when the load directed to the system continues to increase, it’s bound to hit that limit sooner or later. But an organic increase in load, that gives the system the time to scale out accordingly and increase its capacity, is one thing, and a sudden and unexpected flood is another.</p>
<p>For example, consider the number of requests received by an application in a period of time. The rate and the type of incoming requests can change over time, and sometimes suddenly, for a variety of reasons:</p>
<ul>
<li>The requests might have a seasonality. So, for example, depending on the hour of the day, the application is hit by users in different countries.</li>
<li>Some requests are much more expensive than others and abuse the system in unexpected ways, like scrapers slurping in data at super-human speed.</li>
<li>Some requests are malicious, like those of DDoS attacks that try to saturate the application’s bandwidth to deny legitimate users access to it.</li>
</ul>
<p>While some load surges can be handled by automation that adds capacity (e.g., autoscaling), others require the system to reject requests to shield it from overloading, using the patterns we will discuss in chapter <a href="#upstream-resiliency">28</a>.</p>
</section>
<section id="cascading-failures" class="level2" data-number="24.8">
<h2 data-number="24.8"><span class="header-section-number">24.8</span> Cascading failures</h2>
<p>You would think that if a system has hundreds of processes, it shouldn’t make much of a difference if a small percentage are slow or unreachable. The thing about faults is that they have the potential to spread virally and cascade from one process to the other until the whole system crumbles to its knees. This happens when system components depend on each other, and a failure in one increases the probability of failure in others.</p>
<p>For example, suppose multiple clients are querying two database replicas, A and B, behind a load balancer. Each replica handles about 50 transactions per second (see Figure <a href="#fig:cascadingfailure1">24.1</a>).</p>
<div class="figure" style="text-align: center">
<img alt="Two replicas behind a load balancer; each is handling half the load." width="65%" src="../media/file61.png" />
<p class="caption">
Figure 24.1: Two replicas behind a load balancer; each is handling half the load.
</p>
</div>
<p>Suddenly, replica B becomes unavailable because of a network fault. The load balancer detects that B is unavailable and removes it from the pool. Because of that, replica A has to pick up the slack for B and serve twice the requests per unit time it was serving before (see Figure <a href="#fig:cascadingfailure2">24.2</a>).</p>
<div class="figure" style="text-align: center">
<img alt="When replica B becomes unavailable, A will be hit with more load, which can strain it beyond its capacity." width="60%" src="../media/file62.png" />
<p class="caption">
Figure 24.2: When replica B becomes unavailable, A will be hit with more load, which can strain it beyond its capacity.
</p>
</div>
<p>If replica A struggles to keep up with the incoming requests, the clients will experience increasingly more timeouts and start to retry requests, adding more load to the system. Eventually, replica A will be under so much load that most requests will time out, forcing the load balancer to remove it from the pool. In other words, the original network fault that caused replica B to become unavailable cascaded into a fault at replica A.</p>
<p>Suppose now that replica B becomes available again and the load balancer puts it back in the pool. Because it’s the only replica in the pool, it will be flooded with requests, causing it to overload and eventually be removed again.</p>
<p>You can see how even after the network fault is gone, the application continues to struggle because of a feedback loop that causes the load to jump from one replica to another. Failures with this characteristic are also referred to as metastable<a href="#fn12" class="footnote-ref" id="fnref12" epub:type="noteref">12</a>.</p>
<p>A big enough corrective action is usually needed to break the loop, like temporarily blocking traffic from getting to the replicas in the first place. Unfortunately, these failures are very hard to mitigate once they have started, and the best way to prevent them is to stop faults from spreading from one component to another in the first place.</p>
</section>
<section id="managing-risk" class="level2" data-number="24.9">
<h2 data-number="24.9"><span class="header-section-number">24.9</span> Managing risk</h2>
<p>As it should be evident by now, a distributed application needs to accept that faults are inevitable and be prepared to detect, react to, and repair them as they occur.</p>
<p>At this point, you might feel overwhelmed by the sheer amount of things that can go wrong. But just because a specific fault has a chance of happening, it doesn’t mean we have to do something about it. We first have to consider the probability it will manifest and the impact it will cause to the system’s users when it does. By multiplying the two factors together, we get a risk score<a href="#fn13" class="footnote-ref" id="fnref13" epub:type="noteref">13</a> that we can use to prioritize which faults to address (see Figure <a href="#fig:risk">24.3</a>) first. For example, a fault that is very likely to happen, and has a large impact, should be tackled head on; on the other hand, a fault with a low likelihood and low impact can wait.</p>
<div class="figure" style="text-align: center">
<img alt="Risk matrix" width="100%" src="../media/file63.png" />
<p class="caption">
Figure 24.3: Risk matrix
</p>
</div>
<p>Once we decide that we need to do something about a specific fault, we can try to reduce its probability and/or reduce its impact. This will be the main focus of the next chapters.</p>
</section>
</section>
<section class="footnotes" epub:type="footnotes">
<hr />
<ol>
<li id="fn1" epub:type="footnote"><p>“A Conceptual Framework for System Fault Tolerance,” <a href="https://resources.sei.cmu.edu/asset_files/TechnicalReport/1992_005_001_16112.pdf" class="uri">https://resources.sei.cmu.edu/asset_files/TechnicalReport/1992_005_001_16112.pdf</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" epub:type="footnote"><p>“Simple Testing Can Prevent Most Critical Failures: An Analysis of Production Failures in Distributed Data-Intensive Systems,” <a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-yuan.pdf" class="uri">https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-yuan.pdf</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" epub:type="footnote"><p>This is the reason the Go language puts so much emphasis on error handling.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" epub:type="footnote"><p>“A List of Post-mortems: Config Errors,” <a href="https://github.com/danluu/post-mortems#config-errors" class="uri">https://github.com/danluu/post-mortems#config-errors</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" epub:type="footnote"><p>“Early Detection of Configuration Errors to Reduce Failure Damage,” <a href="https://www.usenix.org/system/files/conference/osdi16/osdi16-xu.pdf" class="uri">https://www.usenix.org/system/files/conference/osdi16/osdi16-xu.pdf</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" epub:type="footnote"><p>“It’s always DNS,” <a href="https://twitter.com/ahidalgosre/status/1315345619926609920?lang=en-GB" class="uri">https://twitter.com/ahidalgosre/status/1315345619926609920?lang=en-GB</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" epub:type="footnote"><p>“Foursquare Goes Dark Too. Unintentionally.,” <a href="https://techcrunch.com/2010/03/27/foursquare-offline" class="uri">https://techcrunch.com/2010/03/27/foursquare-offline</a><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" epub:type="footnote"><p>“Stop using .IO Domain Names for Production Traffic,” <a href="https://hackernoon.com/stop-using-io-domain-names-for-production-traffic-b6aa17eeac20" class="uri">https://hackernoon.com/stop-using-io-domain-names-for-production-traffic-b6aa17eeac20</a><a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" epub:type="footnote"><p>“Microsoft Teams goes down after Microsoft forgot to renew a certificate,” <a href="https://www.theverge.com/2020/2/3/21120248/microsoft-teams-down-outage-certificate-issue-status" class="uri">https://www.theverge.com/2020/2/3/21120248/microsoft-teams-down-outage-certificate-issue-status</a><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" epub:type="footnote"><p>“Fallacies of distributed computing,” <a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing" class="uri">https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing</a><a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" epub:type="footnote"><p>“Gray Failure: The Achilles’ Heel of Cloud-Scale Systems,” <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/paper-1.pdf" class="uri">https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/paper-1.pdf</a><a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" epub:type="footnote"><p>“Metastable Failures in Distributed Systems,” <a href="https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s11-bronson.pdf" class="uri">https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s11-bronson.pdf</a><a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" epub:type="footnote"><p>“Risk matrix,” <a href="https://en.wikipedia.org/wiki/Risk_matrix" class="uri">https://en.wikipedia.org/wiki/Risk_matrix</a><a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
