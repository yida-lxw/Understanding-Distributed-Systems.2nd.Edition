<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en-GB">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <title>ch009.xhtml</title>
  <link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css" />
</head>
<body epub:type="bodymatter">
<section id="tcp" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> 可靠的链接</h1>
<p>在网络层，两个节点之间的通信是通过将数据包从一个路由器路由到下一个路由器来实现的。为此需要两个要素：节点寻址的方法，以及在路由器之间路由数据包的机制。</p>
<p>寻址功能由IP协议负责处理。例如，IPv6提供128位地址空间，可支持<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mn>2</mn><mn>128</mn></msup><annotation encoding="application/x-tex">2^{128}</annotation></semantics></math>个地址。路由器需要通过查询本地路由表来决定数据包的转发路径，该路由表将目标地址映射至通往该目的地的下一跳路由器地址。而构建路由表并在路由器之间传递路由信息的职责，则由边界网关协议(BGP<a href="#fn1" class="footnote-ref" id="fnref1" epub:type="noteref">1</a>)承担。</p>
<p>目前，IP协议并不保证互联网上发送的数据一定能到达目的地。例如，当路由器过载时，就可能会开始丢弃数据包。这时就需要TCP<sup><a href="#fn2" id="fnref2">2</a></sup>协议发挥作用——这个传输层协议在上层IP协议之上，为两个进程之间暴露了可靠的通信信道。TCP协议能确保字节流按顺序到达，不丢包、不重复、无损坏。同时TCP还实现了一套稳定性模式，以避免网络和接收方过载。</p>
<section id="reliability" class="level2" data-number="2.1">
<h2 data-number="2.1"><span class="header-section-number">2.1</span> 可靠性</h2>
<p>TCP通过将字节流分割为称为报文段的独立数据包，来营造可靠信道的假象。每个报文段都带有顺序编号，这使得接收方能检测出数据丢包和重复数据。所有发出的报文段都必须得到接收方的确认应答，若未收到应答，发送端的计时器会触发并重传该报文段。为确保数据传输过程中未被篡改，接收方会通过校验和来验证报文段的完整性。</p>
</section>
<section id="connection-lifecycle" class="level2" data-number="2.2">
<h2 data-number="2.2"><span class="header-section-number">2.2</span> 连接生命周期</h2>

<p>在TCP信道上传输任何数据之前，需要打开连接。操作系统通过<em>套接字</em>管理两端的连接状态。套接字在其生命周期内跟踪连接状态的变化。站在更高级别的角度思考，连接可以处于以下三种状态：</p>
<ul>
<li>打开状态：当连接被创建时处于的状态。</li>
<li>建立状态：当连接被打开，而且数据正在被传输时处于的状态。</li>
<li>关闭状态：当连接被关闭时处于的状态。</li>
</ul>
<p>实际上，这只是一个简化版。因为实际上存在的状态<a href="#fn3" class="footnote-ref" id="fnref3" epub:type="noteref">3</a>比上述的3种状态要多。</p>
<p>服务器必须在建立连接之前监听来自客户端的连接请求。TCP使用三次握手来创建新连接，如图<a href="#fig:handshake">2.1</a>所示：</p>
<ol type="1">
<li>发送者随机选择一个序列号 <em>x</em> 并向接收者发送一个 SYN 报文段。</li>
<li>接收者递增<em>x</em>的值 ，选择一个随机序列号 <em>y</em>，并发送一个 SYN/ACK 报文段作为回应。</li>
<li>发送者将两个序列号都递增，并回复一个 ACK 报文段以及应用数据的第一个字节。</li>
</ol>
<p>TCP使用序列号来保证数据按顺序传输并且没有数据丢包。</p>
<div class="figure" style="text-align: center">
<img alt="Three-way handshake" width="100%" src="../media/file3.png" />
<p class="caption">
图 2.1: 3次握手
</p>
</div>

<p>握手过程引入了一个完整的往返周期，期间不发送任何应用数据。因此在连接建立之前，带宽实际上为零。往返时延(RTT)越低，连接建立速度越快。由此可见，将服务器部署在靠近客户端的位置有助于降低这种冷启动的开销。</p>
<p>数据传输完成后，需要关闭连接以释放两端的资源。这个终止阶段涉及多次往返通信。如果短期内可能再次传输数据，保持连接处于打开状态可以避免重复经历冷启动过程。</p>
<p>此外，关闭套接字并不会立即释放它——套接字会进入持续数分钟的等待状态(<em>TIME_WAIT</em>)，在此期间会丢弃接收到的所有报文段。这种等待机制可以防止已关闭连接的延迟报文段被误认为属于新连接的。但如果大量连接频繁打开和关闭，处于等待状态的套接字数量将持续增加，直到达到最大可打开的套接字数量，从而导致新连接创建失败。这正是一般进程会维护连接池以避免重复创建连接的另一个重要原因。</p>

</section>
<section id="flow-control" class="level2" data-number="2.3">
<h2 data-number="2.3"><span class="header-section-number">2.3</span> 流量控制</h2>
<p>流量控制是TCP采用的一种退避机制，用于防止发送方传输过快导致接收方过载。接收方会将应用程序尚未处理的TCP数据包暂存在接收缓冲区中，如图<a href="#fig:rcwnd">2.2</a>所示。</p>
<div class="figure" style="text-align: center">
<img alt="The receive buffer stores data that hasn&#39;t yet been processed by the destination process." width="100%" src="../media/file4.png" />
<p class="caption">
图 2.2: 接收缓冲区存储尚未被目标进程处理的数据。
</p>
</div>

<p>每当接收方确认一个报文段时，接收方还会将缓冲区的大小传递给发送方，如图<a href="#fig:rcwnd1">2.3</a>所示。假设它遵守协议，则发送方会避免发送超出接收方缓冲区容量的数据。</p>
<div class="figure" style="text-align: center">

<img alt="接收缓冲区的大小存储在确认报文段的header部分进行通信。" width="100%" src="../media/file5.png" />
<p class="caption">
图 2.3: 接收缓冲区的大小存储在确认报文段的header部分进行通信。
</p>
</div>
<p>此机制与在服务级别的速率限制机制并不太相似，该机制在超过特定配额时拒绝请求(见第<a href="#ratelimiting">28.3</a>章节)。但是，与基于API密钥或IP地址的速率限制不同，TCP是在连接级别进行速率限制。</p>
</section>
<section id="congestion-control" class="level2" data-number="2.4">
<h2 data-number="2.4"><span class="header-section-number">2.4</span> 拥塞控制</h2>
<p>TCP不仅能防止接收方过载，还能避免底层网络拥塞。发送方维护一个所谓的<em>拥塞窗口</em>，表示在未收到对方确认的情况下可以发送的最大数据段数量。拥塞窗口越小，同一时刻传输中的数据量就越少，占用的带宽也就越低。</p> 
<p>当新链接建立时，拥塞窗口大小会被设为系统默认值。之后每接收到一个数据段的确认，窗口大小就会指数级增长，直到达到上限。这意味着连接刚建立时无法立即使用网络的全部带宽。如图<a href="#fig:congestion">2.4</a>所示，往返时延(RTT)越短，发送方就能越快利用底层网络的带宽。</p>
<div class="figure" style="text-align: center">
<img alt="RTT越短，发送者就能越快开始利用底层网络的带宽。" width="100%" src="../media/file6.png" />
<p class="caption">
图 2.4: RTT越短，发送者就能越快开始利用底层网络的带宽。
</p>
</div>

<p>如果报文段丢失了会发生什么？当发送方通过超时检测到一个确认报文段丢失时，就会触发<em>拥塞避免</em>机制，拥塞窗口的大小会被减小。此后，随着时间推移，窗口大小<a href="#fn4" class="footnote-ref" id="fnref4" epub:type="noteref">4</a>会按一定量增加，而超时则会使窗口大小按一定量减少。</p> 
<p>如前所述，拥塞窗口的大小定义了在未收到确认报文段的情况下可以发送的最大数据量。由于发送方需要等待完整的往返时延才能获得确认报文段，因此我们可以通过将拥塞窗口的大小除以往返时延来推导出最大理论带宽：</p>

<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">带宽</mtext><mo>=</mo><mfrac><mtext mathvariant="normal">窗口大小</mtext><mtext mathvariant="normal">往返时延(RTT)</mtext></mfrac></mrow><annotation encoding="application/x-tex">
\text{带宽} = \frac{\text{窗口大小}}{\text{往返时延(RTT)}}
</annotation></semantics></math></p>

<p>该公式<a href="#fn5" class="footnote-ref" id="fnref5" epub:type="noteref">5</a>表明带宽是关于往返时延(RTT)的函数。由于TCP无法改变往返时延，因此会极力优化窗口大小。然而，这并不总能得到最优配置。由于拥塞控制的工作方式的缘故，往返时延越短，底层网络带宽的利用率就越高。这进一步说明了将服务器部署在靠近客户端地理位置的重要性。</p>

</section>
<section id="custom-protocols" class="level2" data-number="2.5">
<h2 data-number="2.5"><span class="header-section-number">2.5</span> 自定义协议</h2>

<p>TCP的可靠性和稳定性是以牺牲带宽和增加延迟为代价的，其实际性能往往低于底层网络的物理极限。如果我们舍弃TCP提供的稳定性和可靠性机制，得到的就是一个名为<em>用户数据报协议</em><a href="#fn6" class="footnote-ref" id="fnref6" epub:type="noteref">6</a>(UDP)的简易协议 — 这是一种无连接的传输层协议，可作为TCP的替代方案。</p> <p>与TCP不同，UDP不会向客户端提供字节流抽象。因此，客户端只能发送称为<em>数据报</em>的有限大小离散数据包。UDP不提供任何可靠性保证，因为数据报既没有序列号也不需要确认应答。UDP也不实现流量控制和拥塞控制。总体而言，UDP是一种轻量级的基础协议，通常用于构建自定义协议，这些协议仅提供TCP部分(而非全部)的稳定性和可靠性保证<a href="#fn7" class="footnote-ref" id="fnref7" epub:type="noteref">7</a>。</p> 
<p>比如，在多人在线游戏中,客户端每秒多次采集手柄事件并发送给记录全局游戏状态的服务器，服务器同样会每秒多次采集游戏状态并将快照发回客户端。如果某个快照在传输过程中丢失，重传将毫无价值——因为游戏是实时演进的，当重传的快照到达时早已过时。这正是UDP大显身手的场景；相比之下，TCP会坚持重传丢失数据，反而会降低游戏体验。</p>

</section>
</section>
<section class="footnotes" epub:type="footnotes">
<hr />
<ol>
<li id="fn1" epub:type="footnote"><p>“RFC 4271: 边界网关协议 4 (BGP-4),” <a href="https://datatracker.ietf.org/doc/html/rfc4271" class="uri">https://datatracker.ietf.org/doc/html/rfc4271</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" epub:type="footnote"><p>“RFC 793: 传输控制协议,” <a href="https://tools.ietf.org/html/rfc793" class="uri">https://tools.ietf.org/html/rfc793</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" epub:type="footnote"><p>“TCP状态图,” <a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#/media/File:Tcp_state_diagram_fixed_new.svg" class="uri">https://en.wikipedia.org/wiki/Transmission_Control_Protocol#/media/File:Tcp_state_diagram_fixed_new.svg</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" epub:type="footnote"><p>“CUBIC: 一种新型的对TCP友好的高速TCP变体,” <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.3152&amp;rep=rep1&amp;type=pdf" class="uri">https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.3152&amp;rep=rep1&amp;type=pdf</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" epub:type="footnote"><p>“带宽时延积,” <a href="https://en.wikipedia.org/wiki/Bandwidth-delay_product" class="uri">https://en.wikipedia.org/wiki/Bandwidth-delay_product</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" epub:type="footnote"><p>“RFC 768: 用户数据报协议,” <a href="https://datatracker.ietf.org/doc/html/rfc768" class="uri">https://datatracker.ietf.org/doc/html/rfc768</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" epub:type="footnote"><p>正如我们稍后将看到的那样，HTT3基于DPP实现，以规避TCP的一些缺点<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
