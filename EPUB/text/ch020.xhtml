<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en-GB">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <title>ch020.xhtml</title>
  <link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css" />
</head>
<body epub:type="bodymatter">
<section id="replication" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Replication</h1>
<p>Data replication is a fundamental building block of distributed systems. One reason for replicating data is to increase availability. If some data is stored exclusively on a single process, and that process goes down, the data won’t be accessible anymore. However, if the data is replicated, clients can seamlessly switch to a copy. Another reason for replication is to increase scalability and performance; the more replicas there are, the more clients can access the data concurrently.</p>
<p>Implementing replication is challenging because it requires keeping replicas consistent with one another even in the face of failures. In this chapter, we will explore Raft’s replication algorithm<a href="#fn1" class="footnote-ref" id="fnref1" epub:type="noteref">1</a>, a replication protocol that provides the strongest consistency guarantee possible — the guarantee that to the clients, the data appears to be stored on a single process, even if it’s actually replicated. Arguably, the most popular protocol that offers this guarantee is Paxos<a href="#fn2" class="footnote-ref" id="fnref2" epub:type="noteref">2</a>, but we will discuss Raft as it’s more understandable.</p>
<p>Raft is based on a mechanism known as <em>state machine replication</em>. The main idea is that a single process, the leader, <em>broadcasts</em> operations that change its state to other processes, the followers (or replicas). If the followers execute the same sequence of operations as the leader, then each follower will end up in the same state as the leader. Unfortunately, the leader can’t simply broadcast operations to the followers and call it a day, as any process can fail at any time, and the network can lose messages. This is why a large part of the algorithm is dedicated to fault tolerance.</p>
<p>The reason why this this mechanism is called stated machine replication is that each process is modeled as a <em>state machine</em><a href="#fn3" class="footnote-ref" id="fnref3" epub:type="noteref">3</a> that transitions from one state to another in response to some input (an operation). If the state machines are <em>deterministic</em> and get exactly the same input in the same order, their states are consistent. That way, if one of them fails, a redundant copy is available from any of the other state machines. State machine replication is a very powerful tool to make a service fault-tolerant as long it can be modeled as a state machine.</p>
<p>For example, consider the problem of implementing a fault-tolerant key-value store. In this case, each state machine represents a storage node that accepts <em>put(k, v)</em> and <em>get(k)</em> operations. The actual state is represented with a dictionary. When a <em>put</em> operation is executed, the key-value pair is added to the dictionary. When a <em>get</em> operation is executed, the value corresponding to the requested key is returned. You can see how if every node executes the same sequence of <em>puts</em>, all nodes will end up having the same state.</p>
<p>In the next section, we will take a deeper look at Raft’s replication protocol. It’s a challenging read that requires to pause and think, but I can assure you it’s well worth the effort, especially if you haven’t seen a replication protocol before.</p>
<section id="stm" class="level2" data-number="10.1">
<h2 data-number="10.1"><span class="header-section-number">10.1</span> State machine replication</h2>
<p>When the system starts up, a leader is elected using Raft’s leader election algorithm discussed in chapter <a href="#leader">9</a>, which doesn’t require any external dependencies. The leader is the only process that can change the replicated state. It does so by storing the sequence of operations that alter the state into a local <em>log</em>, which it replicates to the followers. Replicating the log is what allows the state to be kept in sync across processes.</p>
<p>As shown in Figure <a href="#fig:raft-log">10.1</a>, a log is an ordered list of entries where each entry includes:</p>
<ul>
<li>the operation to be applied to the state, like the assignment of 3 to x. The operation needs to be deterministic so that all followers end up in the same state, but it can be arbitrarily complex as long as that requirement is respected (e.g., compare-and-swap or a transaction with multiple operations);</li>
<li>the index of the entry’s position in the log;</li>
<li>and the leader’s election term (the number in each box).</li>
</ul>
<div class="figure" style="text-align: center">
<img alt="The leader&#39;s log is replicated to its followers." width="100%" src="../media/file14.png" />
<p class="caption">
Figure 10.1: The leader’s log is replicated to its followers.
</p>
</div>
<p>When the leader wants to apply an operation to its local state, it first appends a new entry for the operation to its log. At this point, the operation hasn’t been applied to the local state just yet; it has only been logged.</p>
<p>The leader then sends an <em>AppendEntries</em> request to each follower with the new entry to be added. This message is also sent out periodically, even in the absence of new entries, as it acts as a <em>heartbeat</em> for the leader.</p>
<p>When a follower receives an <em>AppendEntries</em> request, it appends the entry it received to its own log (without actually executing the operation yet) and sends back a response to the leader to acknowledge that the request was successful. When the leader hears back successfully from a majority of followers, it considers the entry to be committed and executes the operation on its local state. The leader keeps track of the highest committed index in the log, which is sent in all future <em>AppendEntries</em> requests. A follower only applies a log entry to its local state when it finds out that the leader has committed the entry.</p>
<p>Because the leader needs to wait for <em>only</em> a majority (quorum) of followers, it can make progress even if some are down, i.e., if there are <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>f</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2f + 1</annotation></semantics></math> followers, the system can tolerate up to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> failures. The algorithm guarantees that an entry that is committed is durable and will eventually be executed by all the processes in the system, not just those that were part of the original majority.</p>
<p>So far, we have assumed there are no failures, and the network is reliable. Let’s relax those assumptions. If the leader fails, a follower is elected as the new leader. But, there is a caveat: because the replication algorithm only needs a majority of processes to make progress, it’s possible that some processes are not up to date when a leader fails. To avoid an out-of-date process becoming the leader, a process can’t vote for one with a less up-to-date log. In other words, a process can’t win an election if it doesn’t contain all committed entries.</p>
<p>To determine which of two processes’ logs is more up-to-date, the election term and index of their last entries are compared. If the logs end with different terms, the log with the higher term is more up to date. If the logs end with the same term, whichever log is longer is more up to date. Since the election requires a majority vote, and a candidate’s log must be at least as up to date as any other process in that majority to win the election, the elected process will contain all committed entries.</p>
<p>If an <em>AppendEntries</em> request can’t be delivered to one or more followers, the leader will retry sending it indefinitely until a majority of the followers have successfully appended it to their logs. Retries are harmless as <em>AppendEntries</em> requests are idempotent, and followers ignore log entries that have already been appended to their logs.</p>
<p>If a follower that was temporarily unavailable comes back online, it will eventually receive an <em>AppendEntries</em> message with a log entry from the leader. The <em>AppendEntries</em> message includes the index and term number of the entry in the log that immediately precedes the one to be appended. If the follower can’t find a log entry with that index and term number, it rejects the message to prevent creating a gap in its log.</p>
<p>When the <em>AppendEntries</em> request is rejected, the leader retries the request, this time including the last two log entries — this is why we referred to the request as <em>AppendEntries</em> and not as <em>AppendEntry</em>. If that fails, the leader retries sending the last three log entries and so forth.<a href="#fn4" class="footnote-ref" id="fnref4" epub:type="noteref">4</a> The goal is for the leader to find the latest log entry where the two logs agree, delete any entries in the follower’s log after that point, and append to the follower’s log all of the leader’s entries after it.</p>
</section>
<section id="consensus" class="level2" data-number="10.2">
<h2 data-number="10.2"><span class="header-section-number">10.2</span> Consensus</h2>
<p>By solving state machine replication, we actually found a solution to <em>consensus</em><a href="#fn5" class="footnote-ref" id="fnref5" epub:type="noteref">5</a> — a fundamental problem studied in distributed systems research in which a group of processes has to decide a value so that:</p>
<ul>
<li>every non-faulty process eventually agrees on a value;</li>
<li>the final decision of every non-faulty process is the same everywhere;</li>
<li>and the value that has been agreed on has been proposed by a process.</li>
</ul>
<p>This may sound a little bit abstract. Another way to think about consensus is as the API of a write-once register<a href="#fn6" class="footnote-ref" id="fnref6" epub:type="noteref">6</a> (WOR): a thread-safe and linearizable<a href="#fn7" class="footnote-ref" id="fnref7" epub:type="noteref">7</a> register that can only be written once but can be read many times.</p>
<p>There are plenty of practical applications of consensus. For example, agreeing on which process in a group can acquire a lease requires consensus. And, as mentioned earlier, state machine replication also requires it. If you squint a little, you should be able to see how the replicated log in Raft is a sequence of WORs, and so Raft really is just a sequence of consensus instances.</p>
<p>While it’s important to understand what consensus is and how it can be solved, you will likely never need to implement it from scratch<a href="#fn8" class="footnote-ref" id="fnref8" epub:type="noteref">8</a>. Instead, you can use one of the many off-the-shelf solutions available.</p>
<p>For example, one of the most common uses of consensus is for coordination purposes, like the election of a leader. As discussed in <a href="#lease">9.2</a>, leader election can be implemented by acquiring a lease. The lease ensures that at most one process can be the leader at any time and if the process dies, another one can take its place. However, this mechanism requires the lease manager, or coordination service, to be fault-tolerant. Etcd<a href="#fn9" class="footnote-ref" id="fnref9" epub:type="noteref">9</a> and ZooKeeper<a href="#fn10" class="footnote-ref" id="fnref10" epub:type="noteref">10</a> are two widely used coordination services that replicate their state for fault-tolerance using consensus. A coordination service exposes a hierarchical, key-value store through its API, and also allows clients to watch for changes to keys. So, for example, acquiring a lease can be implemented by having a client attempt to create a key with a specific TTL. If the key already exists, the operation fails guaranteeing that only one client can acquire the lease.</p>
</section>
<section id="consistency-models" class="level2" data-number="10.3">
<h2 data-number="10.3"><span class="header-section-number">10.3</span> Consistency models</h2>
<p>We discussed state machine replication with the goal of implementing a data store that can withstand failures and scale out to serve a larger number of requests. Now that we know how to build a replicated data store in principle, let’s take a closer look at what happens when a client sends a request to it. In an ideal world, the request executes instantaneously, as shown in Figure <a href="#fig:ideal">10.2</a>.</p>
<div class="figure" style="text-align: center">
<img alt="A write request executing instantaneously" width="100%" src="../media/file15.png" />
<p class="caption">
Figure 10.2: A write request executing instantaneously
</p>
</div>
<p>But in reality, things are quite different — the request needs to reach the leader, which has to process it and send back a response to the client. As shown in Figure <a href="#fig:cones">10.3</a>, these actions take time and are not instantaneous.</p>
<div class="figure" style="text-align: center">
<img alt="A write request can&#39;t execute instantaneously because it takes time to reach the leader and be executed." width="100%" src="../media/file16.png" />
<p class="caption">
Figure 10.3: A write request can’t execute instantaneously because it takes time to reach the leader and be executed.
</p>
</div>
<p>The best guarantee the system can provide is that the request executes somewhere between its invocation and completion time. You might think that this doesn’t look like a big deal; after all, it’s what you are used to when writing single-threaded applications. For example, if you assign 42 to x and read its value immediately afterward, you expect to find 42 in there, assuming there is no other thread writing to the same variable. But when you deal with replicated systems, all bets are off. Let’s see why that’s the case.</p>
<p>In section <a href="#stm">10.1</a>, we looked at how Raft replicates the leader’s state to its followers. Since only the leader can make changes to the state, any operation that modifies it needs to necessarily go through the leader. But what about reads? They don’t necessarily have to go through the leader as they don’t affect the system’s state. Reads can be served by the leader, a follower, or a combination of leader and followers. If all reads have to go through the leader, the read throughput would be limited to that of a single process. But, if any follower can serve reads instead, then two clients, or observers, can have a different view of the system’s state since followers can lag behind the leader.</p>
<p>Intuitively, there is a tradeoff between how consistent the observers’ views of the system are and the system’s performance and availability. To understand this relationship, we need to define precisely what we mean by consistency. We will do so with the help of <em>consistency models</em><a href="#fn11" class="footnote-ref" id="fnref11" epub:type="noteref">11</a>, which formally define the possible views the observers can have of the system’s state.</p>
<section id="linearizability" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1"><span class="header-section-number">10.3.1</span> Strong consistency</h3>
<p>If clients send writes and reads exclusively to the leader, then every request appears to take place atomically at a very specific point in time as if there were a single copy of the data. No matter how many replicas there are or how far behind they are lagging, as long as the clients always query the leader directly, there is a single copy of the data from their point of view.</p>
<p>Because a request is not served instantaneously, and there is a single process that can serve it, the request executes somewhere between its invocation and completion time. By the time it completes, its side-effects are visible to all observers, as shown in Figure <a href="#fig:linearizability">10.4</a>.</p>
<div class="figure" style="text-align: center">
<img alt="The side-effects of a strongly consistent operation are visible to all observers once it completes." width="100%" src="../media/file17.png" />
<p class="caption">
Figure 10.4: The side-effects of a strongly consistent operation are visible to all observers once it completes.
</p>
</div>
<p>Since a request becomes visible to all other participants between its invocation and completion time, a real-time guarantee must be enforced; this guarantee is formalized by a consistency model called <em>linearizability</em><a href="#fn12" class="footnote-ref" id="fnref12" epub:type="noteref">12</a>, or <em>strong consistency</em>. Linearizability is the strongest consistency guarantee a system can provide for single-object requests.<a href="#fn13" class="footnote-ref" id="fnref13" epub:type="noteref">13</a></p>
<p>Unfortunately, the leader can’t serve reads directly from its local state because by the time it receives a request from a client, it might no longer be the leader; so, if it were to serve the request, the system wouldn’t be strongly consistent. The presumed leader first needs to contact a majority of replicas to confirm whether it still is the leader. Only then is it allowed to execute the request and send back a response to the client. Otherwise, it transitions to the follower state and fails the request. This confirmation step considerably increases the time required to serve a read.</p>
</section>
<section id="sequential-consistency" class="level3" data-number="10.3.2">
<h3 data-number="10.3.2"><span class="header-section-number">10.3.2</span> Sequential consistency</h3>
<p>So far, we have discussed serializing all reads through the leader. But doing so creates a single chokepoint, limiting the system’s throughput. On top of that, the leader needs to contact a majority of followers to handle a read, which increases the time it takes to process a request. To increase the read performance, we could also allow the followers to handle requests.</p>
<p>Even though a follower can lag behind the leader, it will always receive new updates in the same order as the leader. For example, suppose one client only ever queries follower 1, and another only ever queries follower 2. In that case, the two clients will see the state evolving at different times, as followers are not perfectly in sync (see Figure <a href="#fig:sequential">10.5</a>).</p>
<div class="figure" style="text-align: center">
<img alt="Although followers have a different view of the system’s state, they process updates in the same order." width="100%" src="../media/file18.png" />
<p class="caption">
Figure 10.5: Although followers have a different view of the system’s state, they process updates in the same order.
</p>
</div>
<p>The consistency model that ensures operations occur in the same order for all observers, but doesn’t provide any real-time guarantee about when an operation’s side-effect becomes visible to them, is called <em>sequential consistency</em><a href="#fn14" class="footnote-ref" id="fnref14" epub:type="noteref">14</a>. The lack of real-time guarantees is what differentiates sequential consistency from linearizability.</p>
<p>A producer/consumer system synchronized with a queue is an example of this model; a producer writes items to the queue, which a consumer reads. The producer and the consumer see the items in the same order, but the consumer lags behind the producer.</p>
</section>
<section id="eventual-consistency" class="level3" data-number="10.3.3">
<h3 data-number="10.3.3"><span class="header-section-number">10.3.3</span> Eventual consistency</h3>
<p>Although we managed to increase the read throughput, we had to pin clients to followers — if a follower becomes unavailable, the client loses access to the store. We could increase the availability by allowing the client to query any follower. But this comes at a steep price in terms of consistency. For example, say there are two followers, 1 and 2, where follower 2 lags behind follower 1. If a client queries follower 1 and then follower 2, it will see an earlier state, which can be very confusing. The only guarantee the client has is that eventually all followers will converge to the final state if writes to the system stop. This consistency model is called <em>eventual consistency</em>.</p>
<p>It’s challenging to build applications on top of an eventually consistent data store because the behavior is different from what we are used to when writing single-threaded applications. As a result, subtle bugs can creep up that are hard to debug and reproduce. Yet, in eventual consistency’s defense, not all applications require linearizability. For example, an eventually consistent store is perfectly fine if we want to keep track of the number of users visiting a website, since it doesn’t really matter if a read returns a number that is slightly out of date.</p>
</section>
<section id="the-cap-theorem" class="level3" data-number="10.3.4">
<h3 data-number="10.3.4"><span class="header-section-number">10.3.4</span> The CAP theorem</h3>
<p>When a network partition happens, parts of the system become disconnected from each other. For example, some clients might no longer be able to reach the leader. The system has two choices when this happens; it can either:</p>
<ul>
<li>remain available by allowing clients to query followers that are reachable, sacrificing strong consistency;</li>
<li>or guarantee strong consistency by failing reads that can’t reach the leader.</li>
</ul>
<p>This concept is expressed by the <em>CAP theorem</em><a href="#fn15" class="footnote-ref" id="fnref15" epub:type="noteref">15</a>, which can be summarized as: “strong consistency, availability and partition tolerance: pick two out of three.” In reality, the choice really is only between strong consistency and availability, as network faults are a given and can’t be avoided.</p>
<p>Confusingly enough, the CAP theorem’s definition of availability requires that every request <em>eventually</em> receives a response. But in real systems, achieving perfect availability is impossible. Moreover, a very slow response is just as bad as one that never occurs. So, in other words, many highly-available systems can’t be considered available as defined by the CAP theorem. Similarly, the theorem’s definition of consistency and partition tolerance is very precise, limiting its practical applications.<a href="#fn16" class="footnote-ref" id="fnref16" epub:type="noteref">16</a> A more useful way to think about the relationship between availability and consistency is as a spectrum. And so, for example, a strongly consistent and partition-tolerant system as defined by the CAP theorem occupies just one point in that spectrum.<a href="#fn17" class="footnote-ref" id="fnref17" epub:type="noteref">17</a></p>
<p>Also, even though network partitions can happen, they are usually rare within a data center. But, even in the absence of a network partition, there is a tradeoff between consistency and <em>latency</em> (or performance). The stronger the consistency guarantee is, the higher the latency of individual operations must be. This relationship is expressed by the <em>PACELC theorem</em><a href="#fn18" class="footnote-ref" id="fnref18" epub:type="noteref">18</a>, an extension to the CAP theorem. It states that in case of network partitioning (P), one has to choose between availability (A) and consistency (C), but else (E), even when the system is running normally in the absence of partitions, one has to choose between latency (L) and consistency (C). In practice, the choice between latency and consistency is not binary but rather a spectrum.</p>
<p>This is why some off-the-shelf distributed data stores come with counter-intuitive consistency guarantees in order to provide high availability and performance. Others have knobs that allow you to choose whether you want better performance or stronger consistency guarantees, like Azure’s Cosmos DB<a href="#fn19" class="footnote-ref" id="fnref19" epub:type="noteref">19</a> and Cassandra<a href="#fn20" class="footnote-ref" id="fnref20" epub:type="noteref">20</a>.</p>
<p>Another way to interpret the PACELC theorem is that there is a tradeoff between the amount of coordination required and performance. One way to design around this fundamental limitation is to move coordination away from the critical path. For example, earlier we discussed that for a read to be strongly consistent, the leader has to contact a majority of followers. That coordination tax is paid for each read! In the next section, we will explore a different replication protocol that moves this cost away from the critical path.</p>
</section>
</section>
<section id="chain-replication" class="level2" data-number="10.4">
<h2 data-number="10.4"><span class="header-section-number">10.4</span> Chain replication</h2>
<p>Chain replication<a href="#fn21" class="footnote-ref" id="fnref21" epub:type="noteref">21</a> is a widely used replication protocol that uses a very different topology from leader-based replication protocols like Raft. In chain replication, processes are arranged in a chain. The leftmost process is referred to as the chain’s <em>head</em>, while the rightmost one is the chain’s <em>tail</em>.</p>
<p>Clients send writes exclusively to the head, which updates its local state and forwards the update to the next process in the chain. Similarly, that process updates its state and forwards the change to its successor until it eventually reaches the tail.</p>
<p>When the tail receives an update, it applies it locally and sends an acknowledgment to its predecessor to signal that the change has been committed. The acknowledgment flows back to the head, which can then reply to the client that the write succeeded<a href="#fn22" class="footnote-ref" id="fnref22" epub:type="noteref">22</a>.</p>
<p>Client reads are served exclusively by the tail, as shown in Fig <a href="#fig:CR">10.6</a>. In the absence of failures, the protocol is strongly consistent as all writes and reads are processed one at a time by the tail. But what happens if a process in the chain fails?</p>
<div class="figure" style="text-align: center">
<img alt="Writes propagate through all processes in the chain, while reads are served exclusively by the tail." width="90%" src="../media/file19.png" />
<p class="caption">
Figure 10.6: Writes propagate through all processes in the chain, while reads are served exclusively by the tail.
</p>
</div>
<p>Fault tolerance is delegated to a dedicated component, the configuration manager or <em>control plane</em>. At a high level, the control plane monitors the chain’s health, and when it detects a faulty process, it removes it from the chain. The control plane ensures that there is a single view of the chain’s topology that every process agrees with. For this to work, the control plane needs to be fault-tolerant, which requires state machine replication (e.g., Raft). So while the chain can tolerate up to N − 1 processes failing, where N is the chain’s length, the control plane can only tolerate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mi>C</mi><mn>2</mn></mfrac><annotation encoding="application/x-tex">\frac{C}{2}</annotation></semantics></math> failures, where C is the number of replicas that make up the control plane.</p>
<p>There are three failure modes in chain replication: the head can fail, the tail can fail, or an intermediate process can fail. If the head fails, the control plane removes it by reconfiguring its successor to be the new head and notifying clients of the change. If the head committed a write to its local state but crashed before forwarding it downstream, no harm is done. Since the write didn’t reach the tail, the client that issued it hasn’t received an acknowledgment for it yet. From the client’s perspective, it’s just a request that timed out and needs to be retried. Similarly, no other client will have seen the write’s side effects since it never reached the tail.</p>
<p>If the tail fails, the control plane removes it and makes its predecessor the chain’s new tail. Because all updates that the tail has received must necessarily have been received by the predecessor as well, everything works as expected.</p>
<p>If an intermediate process <em>X</em> fails, the control plane has to link <em>X</em>’s predecessor with <em>X</em>’s successor. This case is a bit trickier to handle since <em>X</em> might have applied some updates locally but failed before forwarding them to its successor. Therefore, <em>X</em>’s successor needs to communicate to the control plane the sequence number of the last committed update it has seen, which is then passed to <em>X</em>’s predecessor to send the missing updates downstream.</p>
<p>Chain replication can tolerate up to N − 1 failures. So, as more processes in the chain fail, it can tolerate fewer failures. This is why it’s important to replace a failing process with a new one. This can be accomplished by making the new process the tail of the chain after syncing it with its predecessor.</p>
<p>The beauty of chain replication is that there are only a handful of simple failure modes to consider. That’s because for a write to commit, it needs to reach the tail, and consequently, it must have been processed by every process in the chain. This is very different from a quorum-based replication protocol like Raft, where only a subset of replicas may have seen a committed write.</p>
<p>Chain replication is simpler to understand and more performant than leader-based replication since the leader’s job of serving client requests is split among the head and the tail. The head sequences writes by updating its local state and forwarding updates to its successor. Reads, however, are served by the tail, and are interleaved with updates received from its predecessor. Unlike in Raft, a read request from a client can be served immediately from the tail’s local state without contacting the other replicas first, which allows for higher throughputs and lower response times.</p>
<p>However, there is a price to pay in terms of write latency. Since an update needs to go through all the processes in the chain before it can be considered committed, a single slow replica can slow down all writes. In contrast, in Raft, the leader only has to wait for a majority of processes to reply and therefore is more resilient to transient degradations. Additionally, if a process isn’t available, chain replication can’t commit writes until the control plane detects the problem and takes the failing process out of the chain. In Raft instead, a single process failing doesn’t stop writes from being committed since only a quorum of processes is needed to make progress.</p>
<p>That said, chain replication allows write requests to be pipelined, which can significantly improve throughput. Moreover, read throughput can be further increased by distributing reads across replicas while still guaranteeing linearizability. The idea is for replicas to store multiple versions of an object, each including a version number and a dirty flag. Replicas mark an update as dirty as it propagates from the head to the tail. Once the tail receives it, it’s considered committed, and the tail sends an acknowledgment back along the chain. When a replica receives an acknowledgment, it marks the corresponding version as clean. Now, when a replica receives a read request for an object, it will immediately serve it if the latest version is clean. If not, it first contacts the tail to request the latest committed version (see Fig <a href="#fig:CRAQ">10.7</a>).</p>
<div class="figure" style="text-align: center">
<img alt="A dirty read can be served by any replica with an additional request to the tail to guarantee strong consistency." width="90%" src="../media/file20.png" />
<p class="caption">
Figure 10.7: A dirty read can be served by any replica with an additional request to the tail to guarantee strong consistency.
</p>
</div>
<p>As discussed in chapter <a href="#leader">9</a>, a leader introduces a scalability bottleneck. But in chain replication, the data plane (i.e., the part of the system that handles individual client requests on the critical path) doesn’t need a leader to do its job since it’s not concerned with failures — its sole focus is throughput and efficiency. On the contrary, the control plane needs a leader to implement state machine replication, but that’s required exclusively to handle the occasional failure and doesn’t affect client requests on the critical path. Another way to think about this is that chain replication reduces the amount of coordination needed for each client request. In turn, this increases the data plane’s capacity to handle load. For this reason, splitting the data plane from the control plane (i.e., the configuration management part) is a common pattern in distributed systems. We will talk in more detail about this in chapter <a href="#controlplane">22</a>.</p>
<p>You might be wondering at this point whether it’s possible to replicate data without needing consensus<a href="#fn23" class="footnote-ref" id="fnref23" epub:type="noteref">23</a> at all to improve performance further. In the next chapter, we will try to do just that.</p>
</section>
</section>
<section class="footnotes" epub:type="footnotes">
<hr />
<ol>
<li id="fn1" epub:type="footnote"><p>“In Search of an Understandable Consensus Algorithm,” <a href="https://raft.github.io/raft.pdf" class="uri">https://raft.github.io/raft.pdf</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" epub:type="footnote"><p>“Paxos Made Simple,” <a href="https://lamport.azurewebsites.net/pubs/paxos-simple.pdf" class="uri">https://lamport.azurewebsites.net/pubs/paxos-simple.pdf</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" epub:type="footnote"><p>“Finite-state machine,” <a href="https://en.wikipedia.org/wiki/Finite-state_machine" class="uri">https://en.wikipedia.org/wiki/Finite-state_machine</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" epub:type="footnote"><p>In practice, there are ways to reduce the number of messages required for this step.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" epub:type="footnote"><p>“Consensus,” <a href="https://en.wikipedia.org/wiki/Consensus_(computer_science)" class="uri">https://en.wikipedia.org/wiki/Consensus_(computer_science)</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" epub:type="footnote"><p>“Paxos made Abstract,” <a href="https://maheshba.bitbucket.io/blog/2021/11/15/Paxos.html" class="uri">https://maheshba.bitbucket.io/blog/2021/11/15/Paxos.html</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" epub:type="footnote"><p>We will define what linearizability means in the next section.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" epub:type="footnote"><p>nor want to, since it’s very challenging to get right; see “Paxos Made Live - An Engineering Perspective,” <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/paxos_made_live.pdf" class="uri">https://static.googleusercontent.com/media/research.google.com/en//archive/paxos_made_live.pdf</a><a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" epub:type="footnote"><p>“etcd: A distributed, reliable key-value store for the most critical data of a distributed system,” <a href="https://etcd.io/" class="uri">https://etcd.io/</a><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" epub:type="footnote"><p>“Apache ZooKeeper: An open-source server which enables highly reliable distributed coordination,” <a href="https://zookeeper.apache.org/" class="uri">https://zookeeper.apache.org/</a><a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" epub:type="footnote"><p>“Consistency Models,” <a href="https://jepsen.io/consistency" class="uri">https://jepsen.io/consistency</a><a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" epub:type="footnote"><p>“Linearizability,” <a href="https://jepsen.io/consistency/models/linearizable" class="uri">https://jepsen.io/consistency/models/linearizable</a><a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" epub:type="footnote"><p>For example, this is the guarantee you would expect from a coordination service that manages leases.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" epub:type="footnote"><p>“Sequential Consistency,” <a href="https://jepsen.io/consistency/models/sequential" class="uri">https://jepsen.io/consistency/models/sequential</a><a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15" epub:type="footnote"><p>“Perspectives on the CAP Theorem,” <a href="https://groups.csail.mit.edu/tds/papers/Gilbert/Brewer2.pdf" class="uri">https://groups.csail.mit.edu/tds/papers/Gilbert/Brewer2.pdf</a><a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16" epub:type="footnote"><p>“A Critique of the CAP Theorem,” <a href="https://www.cl.cam.ac.uk/research/dtg/www/files/publications/public/mk428/cap-critique.pdf" class="uri">https://www.cl.cam.ac.uk/research/dtg/www/files/publications/public/mk428/cap-critique.pdf</a><a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17" epub:type="footnote"><p>“CAP Theorem: You don’t need CP, you don’t want AP, and you can’t have CA,” <a href="https://www.youtube.com/watch?v=hUd_9FENShA" class="uri">https://www.youtube.com/watch?v=hUd_9FENShA</a><a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18" epub:type="footnote"><p>“Consistency Tradeoffs in Modern Distributed Database System Design,” <a href="https://en.wikipedia.org/wiki/PACELC_theorem" class="uri">https://en.wikipedia.org/wiki/PACELC_theorem</a><a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19" epub:type="footnote"><p>“Consistency levels in Azure Cosmos DB,” <a href="https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels" class="uri">https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels</a><a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20" epub:type="footnote"><p>“Apache Cassandra: How is the consistency level configured?,” <a href="https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html" class="uri">https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html</a><a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21" epub:type="footnote"><p>“Chain Replication for Supporting High Throughput and Availability,” <a href="https://www.cs.cornell.edu/home/rvr/papers/OSDI04.pdf" class="uri">https://www.cs.cornell.edu/home/rvr/papers/OSDI04.pdf</a><a href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22" epub:type="footnote"><p>This is slightly different from the original chain replication paper since it’s based on CRAQ, an extension of the original protocol; see “Object Storage on CRAQ,” <a href="https://www.usenix.org/legacy/event/usenix09/tech/full_papers/terrace/terrace.pdf" class="uri">https://www.usenix.org/legacy/event/usenix09/tech/full_papers/terrace/terrace.pdf</a>.<a href="#fnref22" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23" epub:type="footnote"><p>required for state machine replication<a href="#fnref23" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
